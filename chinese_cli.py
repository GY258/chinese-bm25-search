#!/usr/bin/env python3
"""
ä¸­æ–‡BM25æ£€ç´¢æœåŠ¡å‘½ä»¤è¡Œå·¥å…· (Chinese BM25 Retrieval CLI)
"""

import click
import json
from pathlib import Path
from chinese_processor import ChineseDocumentProcessor
from chinese_bm25_search import ChineseBM25Search
from config import ChineseConfig

@click.group()
def cli():
    """ä¸­æ–‡æ–‡æ¡£æ£€ç´¢CLIå·¥å…· (Chinese Document Retrieval CLI)"""
    pass

@cli.command()
def build_index():
    """æ„å»ºä¸­æ–‡æ–‡æ¡£ç´¢å¼• (Build Chinese document index)"""
    try:
        ChineseConfig.create_directories()
        processor = ChineseDocumentProcessor()
        
        print(f"ğŸ” æ‰«æä¸­æ–‡æ–‡æ¡£: {ChineseConfig.DOCUMENTS_DIR}")
        
        if not ChineseConfig.DOCUMENTS_DIR.exists():
            print(f"âŒ æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {ChineseConfig.DOCUMENTS_DIR}")
            return
        
        documents = processor.find_documents(ChineseConfig.DOCUMENTS_DIR)
        
        if not documents:
            print(f"âŒ æœªæ‰¾åˆ°æ–‡æ¡£åœ¨: {ChineseConfig.DOCUMENTS_DIR}")
            print(f"æ”¯æŒçš„æ‰©å±•å: {ChineseConfig.SUPPORTED_EXTENSIONS}")
            return
        
        print(f"ğŸ“„ æ‰¾åˆ° {len(documents)} ä¸ªæ–‡æ¡£")
        
        # Process documents
        document_index, inverted_index = processor.process_documents(documents)
        
        if not document_index:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆæ–‡æ¡£å¯ä»¥å¤„ç†")
            return
        
        # Save index
        processor.save_index(document_index, inverted_index, ChineseConfig.INDEX_DIR)
        
        print(f"\nâœ… ä¸­æ–‡ç´¢å¼•æ„å»ºæˆåŠŸ!")
        print(f"   ç´¢å¼•æ–‡æ¡£æ•°: {len(document_index)}")
        print(f"   è¯æ±‡é‡: {len(inverted_index):,}")
        print(f"   ç´¢å¼•ä¿å­˜åˆ°: {ChineseConfig.INDEX_DIR}")
        
    except Exception as e:
        print(f"âŒ æ„å»ºç´¢å¼•æ—¶å‡ºé”™: {e}")

@cli.command()
@click.argument('query')
@click.option('--limit', default=10, help='æœ€å¤§ç»“æœæ•°é‡')
@click.option('--snippets', is_flag=True, help='åŒ…å«æ–‡æ¡£ç‰‡æ®µ')
def search(query, limit, snippets):
    """æœç´¢ä¸­æ–‡æ–‡æ¡£ (Search Chinese documents)"""
    try:
        processor = ChineseDocumentProcessor()
        
        if not (ChineseConfig.INDEX_DIR / 'chinese_documents.json').exists():
            print("âŒ ç´¢å¼•ä¸å­˜åœ¨ï¼Œè¯·å…ˆä½¿ç”¨ 'build-index' å‘½ä»¤æ„å»ºç´¢å¼•")
            return
        
        document_index, inverted_index = processor.load_index(ChineseConfig.INDEX_DIR)
        search_engine = ChineseBM25Search(document_index, inverted_index)
        
        # Perform search
        results = search_engine.search(query, limit)
        
        if not results:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ°åŒ…å« '{query}' çš„ç»“æœ")
            return
        
        print(f"\nğŸ” æœç´¢ç»“æœ: '{query}'")
        print(f"æ‰¾åˆ° {len(results)} ä¸ªç»“æœ\n")
        
        for i, result in enumerate(results, 1):
            print(f"{i}. {result['title']}")
            print(f"   è¯„åˆ†: {result['score']:.4f} ({result['relevance']})")
            print(f"   è·¯å¾„: {result['path']}")
            print(f"   é•¿åº¦: {result['length']} ä¸ªè¯")
            print(f"   ä¸­æ–‡å­—ç¬¦: {result.get('chinese_chars', 0)} ä¸ª")
            
            if snippets:
                snippet = search_engine.get_chinese_snippet(result['path'], query)
                print(f"   ç‰‡æ®µ: {snippet}")
            
            print()
    
    except Exception as e:
        print(f"âŒ æœç´¢æ—¶å‡ºé”™: {e}")

@cli.command()
@click.argument('term')
def term_stats(term):
    """è·å–ä¸­æ–‡è¯æ±‡ç»Ÿè®¡ (Get Chinese term statistics)"""
    try:
        processor = ChineseDocumentProcessor()
        
        if not (ChineseConfig.INDEX_DIR / 'chinese_documents.json').exists():
            print("âŒ ç´¢å¼•ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ„å»ºç´¢å¼•")
            return
        
        document_index, inverted_index = processor.load_index(ChineseConfig.INDEX_DIR)
        search_engine = ChineseBM25Search(document_index, inverted_index)
        
        stats = search_engine.get_term_statistics(term)
        
        if 'error' in stats:
            print(f"âŒ {stats['error']}")
            return
        
        if stats.get('document_frequency', 0) == 0:
            print(f"âŒ è¯æ±‡ '{term}' ä¸åœ¨ç´¢å¼•ä¸­")
            return
        
        print(f"\nğŸ“Š è¯æ±‡ç»Ÿè®¡: '{stats['term']}'")
        print(f"æ–‡æ¡£é¢‘ç‡: {stats['document_frequency']}")
        print(f"æ€»é¢‘ç‡: {stats['total_frequency']}")
        print(f"IDFè¯„åˆ†: {stats['idf_score']}")
        print(f"è¦†ç›–ç‡: {stats['coverage']}")
        
        if 'documents' in stats and stats['documents']:
            print(f"\nåŒ…å«æ­¤è¯çš„å‰5ä¸ªæ–‡æ¡£:")
            for doc_id, freq in stats['documents']:
                doc_data = document_index[doc_id]
                print(f"  {doc_data['title']} (é¢‘ç‡: {freq})")
    
    except Exception as e:
        print(f"âŒ è·å–è¯æ±‡ç»Ÿè®¡æ—¶å‡ºé”™: {e}")

@cli.command()
def stats():
    """æ˜¾ç¤ºæœç´¢å¼•æ“ç»Ÿè®¡ä¿¡æ¯ (Show search engine statistics)"""
    try:
        processor = ChineseDocumentProcessor()
        
        if not (ChineseConfig.INDEX_DIR / 'chinese_documents.json').exists():
            print("âŒ ç´¢å¼•ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ„å»ºç´¢å¼•")
            return
        
        document_index, inverted_index = processor.load_index(ChineseConfig.INDEX_DIR)
        search_engine = ChineseBM25Search(document_index, inverted_index)
        
        total_chinese_chars = sum(
            doc.get('chinese_chars', 0) 
            for doc in document_index.values()
        )
        
        print(f"\nğŸ“Š ä¸­æ–‡æœç´¢å¼•æ“ç»Ÿè®¡")
        print(f"æ€»æ–‡æ¡£æ•°: {search_engine.num_documents}")
        print(f"è¯æ±‡é‡: {len(search_engine.inverted_index):,}")
        print(f"å¹³å‡æ–‡æ¡£é•¿åº¦: {search_engine.avg_doc_length:.1f} ä¸ªè¯")
        print(f"æ€»ä¸­æ–‡å­—ç¬¦æ•°: {total_chinese_chars:,}")
        print(f"BM25å‚æ•°: k1={search_engine.k1}, b={search_engine.b}")
        print(f"ç´¢å¼•ä½ç½®: {ChineseConfig.INDEX_DIR}")
        
        # Document length distribution
        lengths = [doc['length'] for doc in document_index.values()]
        if lengths:
            lengths.sort()
            print(f"\næ–‡æ¡£é•¿åº¦åˆ†å¸ƒ:")
            print(f"  æœ€çŸ­: {min(lengths)} ä¸ªè¯")
            print(f"  æœ€é•¿: {max(lengths)} ä¸ªè¯")
            print(f"  ä¸­ä½æ•°: {lengths[len(lengths)//2]} ä¸ªè¯")
        
        # Most frequent terms
        term_frequencies = {}
        for term, docs in inverted_index.items():
            term_frequencies[term] = sum(freq for _, freq in docs)
        
        most_common = sorted(term_frequencies.items(), key=lambda x: x[1], reverse=True)[:10]
        
        print(f"\næœ€å¸¸è§è¯æ±‡:")
        for term, freq in most_common:
            print(f"  {term}: {freq}")
    
    except Exception as e:
        print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºé”™: {e}")

@cli.command()
@click.argument('doc_id', type=int)
@click.option('--limit', default=5, help='ç›¸ä¼¼æ–‡æ¡£æ•°é‡')
def similar(doc_id, limit):
    """æŸ¥æ‰¾ç›¸ä¼¼æ–‡æ¡£ (Find similar documents)"""
    try:
        processor = ChineseDocumentProcessor()
        
        if not (ChineseConfig.INDEX_DIR / 'chinese_documents.json').exists():
            print("âŒ ç´¢å¼•ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ„å»ºç´¢å¼•")
            return
        
        document_index, inverted_index = processor.load_index(ChineseConfig.INDEX_DIR)
        search_engine = ChineseBM25Search(document_index, inverted_index)
        
        if doc_id not in document_index:
            print(f"âŒ æ–‡æ¡£ID {doc_id} ä¸å­˜åœ¨")
            return
        
        similar_docs = search_engine.get_similar_documents(doc_id, limit)
        
        source_doc = document_index[doc_id]
        print(f"\nç›¸ä¼¼æ–‡æ¡£: {source_doc['title']}")
        print(f"è·¯å¾„: {source_doc['path']}")
        
        if not similar_docs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼æ–‡æ¡£")
            return
        
        print(f"\næ‰¾åˆ° {len(similar_docs)} ä¸ªç›¸ä¼¼æ–‡æ¡£:")
        
        for i, doc in enumerate(similar_docs, 1):
            print(f"{i}. {doc['title']}")
            print(f"   ç›¸ä¼¼åº¦: {doc['similarity_score']:.4f}")
            print(f"   å…±åŒè¯æ±‡: {doc['shared_terms']} ä¸ª")
            print(f"   è·¯å¾„: {doc['path']}")
            print()
    
    except Exception as e:
        print(f"âŒ æŸ¥æ‰¾ç›¸ä¼¼æ–‡æ¡£æ—¶å‡ºé”™: {e}")

@cli.command()
@click.argument('query')
def analyze(query):
    """åˆ†ææŸ¥è¯¢è¯ (Analyze query)"""
    try:
        processor = ChineseDocumentProcessor()
        
        if not (ChineseConfig.INDEX_DIR / 'chinese_documents.json').exists():
            print("âŒ ç´¢å¼•ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ„å»ºç´¢å¼•")
            return
        
        document_index, inverted_index = processor.load_index(ChineseConfig.INDEX_DIR)
        search_engine = ChineseBM25Search(document_index, inverted_index)
        
        analysis = search_engine.analyze_query(query)
        
        print(f"\nğŸ” æŸ¥è¯¢åˆ†æ: '{analysis['original_query']}'")
        print(f"å¤„ç†åçš„è¯æ±‡: {analysis['processed_terms']}")
        print(f"è¯æ±‡æ•°é‡: {analysis['term_count']}")
        
        print(f"\nè¯æ±‡è¯¦ç»†åˆ†æ:")
        for term_info in analysis['term_analysis']:
            print(f"  '{term_info['term']}':")
            print(f"    é¢‘ç‡: {term_info['frequency']}")
            print(f"    æ–‡æ¡£è¦†ç›–: {term_info['document_coverage']}")
            print(f"    ç¨€æœ‰åº¦: {term_info['rarity_score']}")
    
    except Exception as e:
        print(f"âŒ åˆ†ææŸ¥è¯¢æ—¶å‡ºé”™: {e}")

if __name__ == '__main__':
    cli()
